{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. SMOTE\n",
    "2. AUROC to decide use SMOTE or not\n",
    "3. feature engineering\n",
    "4. feature scaling\n",
    "5. apply machine learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.067</td>\n",
       "      <td>-1.114</td>\n",
       "      <td>-0.616</td>\n",
       "      <td>0.376</td>\n",
       "      <td>1.090</td>\n",
       "      <td>0.467</td>\n",
       "      <td>-0.422</td>\n",
       "      <td>0.460</td>\n",
       "      <td>-0.443</td>\n",
       "      <td>...</td>\n",
       "      <td>0.220</td>\n",
       "      <td>-0.339</td>\n",
       "      <td>0.254</td>\n",
       "      <td>-0.179</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.436</td>\n",
       "      <td>0.958</td>\n",
       "      <td>-0.824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.831</td>\n",
       "      <td>0.271</td>\n",
       "      <td>1.716</td>\n",
       "      <td>1.096</td>\n",
       "      <td>1.731</td>\n",
       "      <td>-0.197</td>\n",
       "      <td>1.904</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>0.557</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.765</td>\n",
       "      <td>-0.735</td>\n",
       "      <td>-1.158</td>\n",
       "      <td>2.554</td>\n",
       "      <td>0.856</td>\n",
       "      <td>-1.506</td>\n",
       "      <td>0.462</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>-1.932</td>\n",
       "      <td>-0.343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.099</td>\n",
       "      <td>1.390</td>\n",
       "      <td>-0.732</td>\n",
       "      <td>-1.065</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.081</td>\n",
       "      <td>-1.450</td>\n",
       "      <td>0.317</td>\n",
       "      <td>-0.624</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.311</td>\n",
       "      <td>0.799</td>\n",
       "      <td>-1.001</td>\n",
       "      <td>1.544</td>\n",
       "      <td>0.575</td>\n",
       "      <td>-0.309</td>\n",
       "      <td>-0.339</td>\n",
       "      <td>-0.148</td>\n",
       "      <td>-0.646</td>\n",
       "      <td>0.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.989</td>\n",
       "      <td>-0.916</td>\n",
       "      <td>-1.343</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.543</td>\n",
       "      <td>0.636</td>\n",
       "      <td>1.127</td>\n",
       "      <td>0.189</td>\n",
       "      <td>-0.118</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.370</td>\n",
       "      <td>1.093</td>\n",
       "      <td>0.596</td>\n",
       "      <td>-0.589</td>\n",
       "      <td>-0.649</td>\n",
       "      <td>-0.163</td>\n",
       "      <td>-0.958</td>\n",
       "      <td>-1.081</td>\n",
       "      <td>0.805</td>\n",
       "      <td>3.401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.811</td>\n",
       "      <td>-1.509</td>\n",
       "      <td>0.522</td>\n",
       "      <td>-0.360</td>\n",
       "      <td>-0.220</td>\n",
       "      <td>-0.959</td>\n",
       "      <td>0.334</td>\n",
       "      <td>-0.566</td>\n",
       "      <td>-0.656</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.178</td>\n",
       "      <td>0.718</td>\n",
       "      <td>-1.017</td>\n",
       "      <td>1.249</td>\n",
       "      <td>-0.596</td>\n",
       "      <td>-0.445</td>\n",
       "      <td>1.751</td>\n",
       "      <td>1.442</td>\n",
       "      <td>-0.393</td>\n",
       "      <td>-0.643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>-0.184</td>\n",
       "      <td>-1.153</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.414</td>\n",
       "      <td>1.557</td>\n",
       "      <td>-0.234</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.896</td>\n",
       "      <td>...</td>\n",
       "      <td>1.492</td>\n",
       "      <td>1.430</td>\n",
       "      <td>-0.333</td>\n",
       "      <td>-0.200</td>\n",
       "      <td>-1.073</td>\n",
       "      <td>0.797</td>\n",
       "      <td>1.980</td>\n",
       "      <td>1.191</td>\n",
       "      <td>1.032</td>\n",
       "      <td>-0.402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.234</td>\n",
       "      <td>-1.373</td>\n",
       "      <td>-2.050</td>\n",
       "      <td>-0.408</td>\n",
       "      <td>-0.255</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.986</td>\n",
       "      <td>-0.891</td>\n",
       "      <td>-0.268</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>0.678</td>\n",
       "      <td>1.395</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.215</td>\n",
       "      <td>-0.537</td>\n",
       "      <td>-1.267</td>\n",
       "      <td>-1.021</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.327</td>\n",
       "      <td>-1.834</td>\n",
       "      <td>-0.762</td>\n",
       "      <td>0.660</td>\n",
       "      <td>-0.858</td>\n",
       "      <td>-2.764</td>\n",
       "      <td>-0.539</td>\n",
       "      <td>-0.065</td>\n",
       "      <td>0.549</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.237</td>\n",
       "      <td>-0.620</td>\n",
       "      <td>0.670</td>\n",
       "      <td>-2.010</td>\n",
       "      <td>0.438</td>\n",
       "      <td>1.972</td>\n",
       "      <td>-0.379</td>\n",
       "      <td>0.676</td>\n",
       "      <td>-1.220</td>\n",
       "      <td>-0.855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.451</td>\n",
       "      <td>-0.204</td>\n",
       "      <td>-0.762</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.022</td>\n",
       "      <td>-1.487</td>\n",
       "      <td>-1.122</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.369</td>\n",
       "      <td>...</td>\n",
       "      <td>0.729</td>\n",
       "      <td>0.411</td>\n",
       "      <td>2.366</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.208</td>\n",
       "      <td>-2.117</td>\n",
       "      <td>-0.546</td>\n",
       "      <td>-0.093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.725</td>\n",
       "      <td>1.064</td>\n",
       "      <td>1.333</td>\n",
       "      <td>-2.863</td>\n",
       "      <td>0.203</td>\n",
       "      <td>1.898</td>\n",
       "      <td>0.434</td>\n",
       "      <td>1.207</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.028</td>\n",
       "      <td>1.081</td>\n",
       "      <td>0.607</td>\n",
       "      <td>0.550</td>\n",
       "      <td>-2.621</td>\n",
       "      <td>-0.143</td>\n",
       "      <td>-0.544</td>\n",
       "      <td>-1.690</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>0.643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     target      0      1      2      3      4      5      6      7      8  \\\n",
       "0       1.0 -1.067 -1.114 -0.616  0.376  1.090  0.467 -0.422  0.460 -0.443   \n",
       "1       0.0 -0.831  0.271  1.716  1.096  1.731 -0.197  1.904 -0.265  0.557   \n",
       "2       0.0  0.099  1.390 -0.732 -1.065  0.005 -0.081 -1.450  0.317 -0.624   \n",
       "3       1.0 -0.989 -0.916 -1.343  0.145  0.543  0.636  1.127  0.189 -0.118   \n",
       "4       0.0  0.811 -1.509  0.522 -0.360 -0.220 -0.959  0.334 -0.566 -0.656   \n",
       "..      ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "245     1.0 -0.068 -0.184 -1.153  0.610  0.414  1.557 -0.234  0.950  0.896   \n",
       "246     0.0 -0.234 -1.373 -2.050 -0.408 -0.255  0.784  0.986 -0.891 -0.268   \n",
       "247     0.0 -2.327 -1.834 -0.762  0.660 -0.858 -2.764 -0.539 -0.065  0.549   \n",
       "248     1.0 -0.451 -0.204 -0.762  0.261  0.022 -1.487 -1.122  0.141  0.369   \n",
       "249     0.0  0.725  1.064  1.333 -2.863  0.203  1.898  0.434  1.207 -0.015   \n",
       "\n",
       "     ...    290    291    292    293    294    295    296    297    298    299  \n",
       "0    ...  0.220 -0.339  0.254 -0.179  0.352  0.125  0.347  0.436  0.958 -0.824  \n",
       "1    ... -0.765 -0.735 -1.158  2.554  0.856 -1.506  0.462 -0.029 -1.932 -0.343  \n",
       "2    ... -1.311  0.799 -1.001  1.544  0.575 -0.309 -0.339 -0.148 -0.646  0.725  \n",
       "3    ... -1.370  1.093  0.596 -0.589 -0.649 -0.163 -0.958 -1.081  0.805  3.401  \n",
       "4    ... -0.178  0.718 -1.017  1.249 -0.596 -0.445  1.751  1.442 -0.393 -0.643  \n",
       "..   ...    ...    ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "245  ...  1.492  1.430 -0.333 -0.200 -1.073  0.797  1.980  1.191  1.032 -0.402  \n",
       "246  ... -0.996  0.678  1.395  0.714  0.215 -0.537 -1.267 -1.021  0.747  0.128  \n",
       "247  ... -1.237 -0.620  0.670 -2.010  0.438  1.972 -0.379  0.676 -1.220 -0.855  \n",
       "248  ...  0.729  0.411  2.366 -0.021  0.160  0.045  0.208 -2.117 -0.546 -0.093  \n",
       "249  ... -1.028  1.081  0.607  0.550 -2.621 -0.143 -0.544 -1.690 -0.198  0.643  \n",
       "\n",
       "[250 rows x 301 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.datasets import make_classification\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the data from the CSV file\n",
    "train_data = pd.read_csv('./dataset/train.csv')\n",
    "df_test = pd.read_csv('./dataset/test.csv')\n",
    "df_train = train_data.drop('id', axis=1, inplace=False)\n",
    "df_test = df_test.drop(['id'], axis=1)\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counter_zero: 183\n",
      "counter_one: 67\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_row = df_train.shape[0]\n",
    "\n",
    "counter_zero = 0\n",
    "counter_one = 0\n",
    "for i in range(0, num_row):\n",
    "    if df_train.iloc[i]['target'] == 0:\n",
    "        counter_zero += 1\n",
    "    elif df_train.iloc[i]['target'] == 1:\n",
    "        counter_one += 1\n",
    "\n",
    "print(\"counter_zero: \" + str(counter_zero))\n",
    "print(\"counter_one: \" + str(counter_one))\n",
    "total_counter = counter_zero + counter_one\n",
    "\n",
    "plt.bar(['0' + '(' + str((counter_zero / total_counter) * 100) + '%)', '1' + '(' + str((counter_one / total_counter) * 100) + '%)'], [counter_zero, counter_one])\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Count of 0 and 1 Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0.0: 183, 1.0: 67})\n",
      "Resampled dataset shape Counter({1.0: 183, 0.0: 183})\n",
      "AUROC on original data: 0.665\n",
      "AUROC on resampled data: 0.950\n"
     ]
    }
   ],
   "source": [
    "# SMOTE (Synthetic Minority Oversampling Techniques)\n",
    "\n",
    "X = df_train.drop('target', axis=1)\n",
    "y = df_train['target']\n",
    "\n",
    "# print class distribution before oversampling\n",
    "print('Original dataset shape %s' % Counter(y))\n",
    "\n",
    "# apply SMOTE oversampling\n",
    "smote = SMOTE()\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Create a new DataFrame that contains both the features and the target variable\n",
    "df_resampled = pd.concat([X_resampled, y_resampled], axis=1)\n",
    "\n",
    "# print class distribution after oversampling\n",
    "print('Resampled dataset shape %s' % Counter(y_resampled))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_proba = clf.predict_proba(X_test)[:,1]\n",
    "auroc_original = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# AUROC of data that being SMOTE\n",
    "X_train_resampled, X_test_resampled, y_train_resampled, y_test_resampled = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "clf_resampled = LogisticRegression()\n",
    "clf_resampled.fit(X_train_resampled, y_train_resampled)\n",
    "y_pred_proba_resampled = clf_resampled.predict_proba(X_test_resampled)[:,1]\n",
    "auroc_resampled = roc_auc_score(y_test_resampled, y_pred_proba_resampled)\n",
    "\n",
    "print(\"AUROC on original data: %.3f\" % auroc_original)\n",
    "print(\"AUROC on resampled data: %.3f\" % auroc_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "\n",
    "# Credits to https://medium.com/analytics-vidhya/kaggle-competition-dont-overfit-ii-74cf2d9deed5\n",
    "def feature_engg(df, if_test = False):\n",
    "    '''\n",
    "    Perform Feature Engg in Basic Stats, Trigometrics, Hyperbolic and Exponential Function\n",
    "    \n",
    "    Parameters:\n",
    "    df: Pass DataFrame (all features much be in numric values)\n",
    "    if_test: If the DataFrame is test data or train data. Ig it is test data, put if_test=True\n",
    "    \n",
    "    Return:\n",
    "    DataFrame with feature engineering appended\n",
    "    '''\n",
    "    \n",
    "    if if_test:\n",
    "        temp = df.drop(['id'], axis=1)\n",
    "    elif not if_test and hasattr(df, 'id') and hasattr(df, 'target'):\n",
    "        temp = df.drop(['id','target'], axis=1)\n",
    "    else:\n",
    "        temp = df\n",
    "        \n",
    "# Mean and Std FE\n",
    "    df['mean'] = np.mean(temp, axis=1)\n",
    "    df['std'] = np.std(temp, axis=1)\n",
    "# Trigometric FE\n",
    "    sin_temp = np.sin(temp)\n",
    "    cos_temp = np.cos(temp)\n",
    "    tan_temp = np.tan(temp)\n",
    "    df['mean_sin'] = np.mean(sin_temp, axis=1)\n",
    "    df['mean_cos'] = np.mean(cos_temp, axis=1)\n",
    "    df['mean_tan'] = np.mean(tan_temp, axis=1)\n",
    "# Hyperbolic FE\n",
    "    sinh_temp = np.sinh(temp)\n",
    "    cosh_temp = np.cosh(temp)\n",
    "    tanh_temp = np.tanh(temp)\n",
    "    df['mean_sinh'] = np.mean(sin_temp, axis=1)\n",
    "    df['mean_cosh'] = np.mean(cos_temp, axis=1)\n",
    "    df['mean_tanh'] = np.mean(tan_temp, axis=1)\n",
    "# Exponents FE\n",
    "    exp_temp = np.exp(temp)\n",
    "    expm1_temp = np.expm1(temp)\n",
    "    exp2_temp = np.exp2(temp)\n",
    "    df['mean_exp'] = np.mean(exp_temp, axis=1)\n",
    "    df['mean_expm1'] = np.mean(expm1_temp, axis=1)\n",
    "    df['mean_exp2'] = np.mean(exp2_temp, axis=1)\n",
    "# Polynomial FE\n",
    "    # X**2\n",
    "    df['mean_x2'] = np.mean(np.power(temp,2), axis=1)\n",
    "    return df\n",
    "\n",
    "df_fe = feature_engg(X_resampled)\n",
    "df_test_fe = feature_engg(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# some values in your DataFrame are too large, possibly infinite or nan.\n",
    "print(np.isinf(df_fe).sum().sum())\n",
    "print(np.isnan(df_fe).sum().sum())\n",
    "\n",
    "for col in df_fe.columns:\n",
    "    col_median = df_fe[col].median()\n",
    "    df_fe[col] = df_fe[col].replace([np.inf, -np.inf], col_median)\n",
    "    df_fe[col] = df_fe[col].fillna(col_median)\n",
    "    \n",
    "for col in df_test_fe.columns:\n",
    "    col_median = df_test_fe[col].median()\n",
    "    df_test_fe[col] = df_test_fe[col].replace([np.inf, -np.inf], col_median)\n",
    "    df_test_fe[col] = df_test_fe[col].fillna(col_median)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_fe_std = scaler.fit_transform(df_fe)\n",
    "df_test_fe_std = scaler.fit_transform(df_test_fe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.500\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# df_resampled = pd.concat([X_resampled, y_resampled], axis=1)\n",
    "target = df_resampled['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_fe_std, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# KNN Classification\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Model Evaluation\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.3f\" % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy in train data: 0.851\n",
      "Accuracy in test data: 0.488\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>250</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>251</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>252</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>253</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>254</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19745</th>\n",
       "      <td>19995</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19746</th>\n",
       "      <td>19996</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19747</th>\n",
       "      <td>19997</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19748</th>\n",
       "      <td>19998</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19749</th>\n",
       "      <td>19999</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19750 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  target\n",
       "0        250     1.0\n",
       "1        251     1.0\n",
       "2        252     0.0\n",
       "3        253     1.0\n",
       "4        254     1.0\n",
       "...      ...     ...\n",
       "19745  19995     0.0\n",
       "19746  19996     1.0\n",
       "19747  19997     1.0\n",
       "19748  19998     1.0\n",
       "19749  19999     0.0\n",
       "\n",
       "[19750 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression on train data set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_fe_std, target, test_size=0.2, random_state=42)\n",
    "\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "y_pred_test = logreg.predict(df_test_fe_std)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy in train data: %.3f\" % accuracy)\n",
    "\n",
    "y_true_test = pd.read_csv('./dataset/sample_submission.csv')['target']\n",
    "accuracy = accuracy_score(y_true_test, y_pred_test)\n",
    "print(\"Accuracy in test data: %.3f\" % accuracy)\n",
    "\n",
    "# create submission file\n",
    "submission = pd.DataFrame({\n",
    "    'id': np.arange(250, 250+len(y_pred_test)),\n",
    "    'target': y_pred_test\n",
    "})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
